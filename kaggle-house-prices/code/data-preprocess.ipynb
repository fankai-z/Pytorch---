{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('pt1': conda)",
   "display_name": "Python 3.8.5 64-bit ('pt1': conda)",
   "metadata": {
    "interpreter": {
     "hash": "606908fc0c26d26e63c369289d4b4eb7ec00ae86ec85f16e9e0fe916ae62f542"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### 1.读取和获取数据集"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext'",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-57-b6defee96d5a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0md2lzh_pytorch\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0md2l\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"..\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pt1/lib/python3.8/site-packages/d2lzh_pytorch/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pt1/lib/python3.8/site-packages/d2lzh_pytorch/utils.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransforms\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtransforms\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtorchtext\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtorchtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvocab\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mVocab\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torchtext'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import d2lzh_pytorch as d2l\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "source": [
    "训练数据集包括1460个样本,80个特征和1个标签  \n",
    "测试数据集包括1459个样本和80个特征"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1460, 81)\n(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "print(train_data.shape)\n",
    "print(test_data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
       "0   1          60       RL         65.0       WD        Normal     208500\n",
       "1   2          20       RL         80.0       WD        Normal     181500\n",
       "2   3          60       RL         68.0       WD        Normal     223500\n",
       "3   4          70       RL         60.0       WD       Abnorml     140000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# 查看前4个特征,后两个特征和标签(SalePrice))\n",
    "train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2919, 79)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "all_features = pd.concat((train_data.iloc[:,1:-1],test_data.iloc[:,1:]))\n",
    "all_features.shape"
   ]
  },
  {
   "source": [
    "### 2.预处理数据"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 对连续数值的特征做标准化　　\n",
    "* 将该特征的每个值先减去均值，再除以标准差．　　　　\n",
    "* 对于缺失的特征值，将其替换成该特征的均值．　　"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n       'MoSold', 'YrSold'],\n      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# dataframe中的字符串dtype=object\n",
    "\n",
    "# pandas.DataFrame.dtypes：pandas提供的这个方法用于返回这个DataFrame中所有列的dtype，以一个pandas.Series形式返回。这个Series的index就是DataFrame的各列名。\n",
    "\n",
    "# numeric_features接受的是数据全部为数字的列名.  \n",
    "# 含NaN的列也为object,(此处有疑问???)\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "print(numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "# 标准化后，均值为０，故直接用０来替换缺失值\n",
    "# (这两个步骤是否考虑换一下???)\n",
    "# fillna(number) 直接对数据块中为NaN替换为0\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)"
   ]
  },
  {
   "source": [
    "#### 将离散数值转成指示特征\n",
    "* 相当于一个onehot操作"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2919, 331)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# dummy_na=True将缺失值也当作合法的特征值并为其创建指示特征\n",
    "# 特征数从79增加到了331\n",
    "all_features = pd.get_dummies(all_features,dummy_na=True)\n",
    "all_features.shape"
   ]
  },
  {
   "source": [
    "* 通过values属性得到numpy格式的数据,并转成Tensor方便后面的训练."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.shape=(1460, 81)\n",
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float)\n",
    "test_features = torch.tensor(all_features[n_train:-1].values, dtype=torch.float)\n",
    "train_labels = torch.tensor(train_data.SalePrice.values, dtype=torch.float)"
   ]
  },
  {
   "source": [
    "### 3.训练模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 使用一个基本的线性回归模型和平方损失函数来训练模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "def get_net(feature_num):\n",
    "    net = nn.Linear(feature_num, 1)\n",
    "    for param in net.parameters():\n",
    "        nn.init.normal_(param, mean=0, std=0.01)\n",
    "    return net"
   ]
  },
  {
   "source": [
    "* 定义从来凭借模型的对数均方根误差\n",
    "\n",
    "``还没看懂?????``  \n",
    "net(features)返回的应该是一个张量,这个张量具体是什么东西."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把features传入到net中,对其输出与labels计算误差\n",
    "def log_mrse(net, features, labels):\n",
    "    with torch.no_grad():\n",
    "        # 将小于1的值设成1,使得取对数时数值更加稳定\n",
    "        clipped_preds = torch.max(net(features), torch.tensor(1.0))\n",
    "        rmse = torch.sqrt(loss(clipped_preds.log(), labels.log()))\n",
    "    return rmse.item()"
   ]
  },
  {
   "source": [
    "``net = net.float()``什么意思?????  \n",
    "``net(X.float())``什么意思??????????,前面并没有对net进行定义."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    # 训练误差和测试误差\n",
    "    train_ls, test_ls = [], []\n",
    "    dataset = torch.utils.data.TensorDataset(train_data, train_labels)\n",
    "    train_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "    # 这里使用了Adam优化算法\n",
    "    optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    net = net.float()\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            l = loss(net(X.float()), y.float)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        train_ls.append(log_mrse(net, train_features, train_labels))\n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_mrse(net, test_features, test_labels))\n",
    "    return train_ls, test_ls\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "### 4.K折交叉验证"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* 得到第i折交叉验证时的训练和验证数据"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_fold_data(k, i, X, y):\n",
    "    # 返回第i折交叉验证时所需要的训练和验证数据\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j+1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train =  X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat((X_train, X_part), dim=0)\n",
    "            y_train = torch.cat((y_train, y_part), dim=0)\n",
    "    return X_train, y_train, X_valid, y_valid\n"
   ]
  },
  {
   "source": [
    "* 在K折交叉验证中我们训练K次并返回训练和验证的平均误差"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "``d21``需要添加,待解决????????"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        net = get_net(X_train.shape[1])\n",
    "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        if i == 0:\n",
    "            d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse',\n",
    "            range(1, num_epochs + 1), valid_ls, ['train', 'valid'])\n",
    "        print('fold %d, train rmse %f, valid rmse %f' % (i, train_ls[-1], valid_ls[-1]))\n",
    "    return train_l_sum / k, valid_l_sum / k\n"
   ]
  },
  {
   "source": [
    "### 5.模型选择"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not callable",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-55-158b86b7a086>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight_decay\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m64\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtrain_l\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_l\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mk_fold\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_features\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight_decay\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'%d-fold validation:avg train rmse %f, avg valid rmse %f'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_l\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_l\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-54-ac68cc1db31b>\u001B[0m in \u001B[0;36mk_fold\u001B[0;34m(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size)\u001B[0m\n\u001B[1;32m      4\u001B[0m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_k_fold_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mnet\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_net\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m         \u001B[0mtrain_ls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_ls\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_rate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight_decay\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m         \u001B[0mtrain_l_sum\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mtrain_ls\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0mvalid_l_sum\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mvalid_ls\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-45-ba6a22be7e9c>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate, weight_decay, batch_size)\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;31m# 训练误差和测试误差\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mtrain_ls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_ls\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensorDataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m     \u001B[0mtrain_iter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataLoader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;31m# 这里使用了Adam优化算法\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pt1/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, *tensors)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mtensors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m         \u001B[0;32massert\u001B[0m \u001B[0mall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensors\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mtensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mtensor\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtensors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    159\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtensors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pt1/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001B[0m in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mtensors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m         \u001B[0;32massert\u001B[0m \u001B[0mall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensors\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mtensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mtensor\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtensors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    159\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtensors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'numpy.int64' object is not callable"
     ]
    }
   ],
   "source": [
    "k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64\n",
    "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)\n",
    "print('%d-fold validation:avg train rmse %f, avg valid rmse %f' % (k, train_l, valid_l))\n"
   ]
  },
  {
   "source": [
    "### 6.预测并提交结果"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "``还未搞懂?????????``"
   ],
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}