{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('pt1': conda)",
   "display_name": "Python 3.8.5 64-bit ('pt1': conda)",
   "metadata": {
    "interpreter": {
     "hash": "606908fc0c26d26e63c369289d4b4eb7ec00ae86ec85f16e9e0fe916ae62f542"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 深度卷积神经网络(AlexNet)\n",
    "\n",
    "* LeNet-5   1998年  \n",
    "通用GPU这个概念在2001年开始兴起,涌现出OpenCL和CUDA之类的编程框架.使得GPU在``2010年前后``开始被机器学习社区使用.  \n",
    "* AlexNet  2012年  \n",
    "首次证明学习到的特征可以超越手工设计的特征.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "在LeNet网络中,可以看到,神经网络可以直接基于图像的原始像素进行分类.这种称为``端到端(end-to-end)``的方法节省了很多中间步骤.  \n",
    "\n",
    "早期的研究过程中,更流行的是研究者通过勤劳所设计并生成的手工特征,这类图像分类研究的主要流程如下:  \n",
    "1.获取图像数据集;  \n",
    "2.使用已有的特征提取函数生成图像特征;  \n",
    "3.使用机器学习模型对图像的特征分类.  \n",
    "\n",
    "\n",
    "机器学习研究者:    致力于使用优雅的定理证明许多``分类器``的性质,机器学习领域生机勃勃,严谨而及其有用.  \n",
    "计算机视觉研究者:  致力于``数据和特征``.即使用干净和较有效的特征甚至比机器学习模型的选择对图像分类结果的影响更大."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### AlexNet\n",
    "* 包含``8层变换``,其中5层卷积和2层全连接隐藏及1层全连接输出.  \n",
    "* 将Sigmoid激活函数换成了更加简单的``ReLU函数``.\n",
    "* 使用了``丢弃法(dropout)``控制全连接层的模型复杂度.\n",
    "* 引入了大量的``图像增广``,如翻转,裁剪和颜色变化,从而进一步``扩大数据集来缓解过拟合``."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            # 减小卷积窗口,增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 接下来连续3个卷积层,前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # 输出层\n",
    "            nn.Linear(4096, 10) # 不经过激活函数的logits\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        ouput = self.fc(feature.view(img.shape[0], -1))\n",
    "        return ouput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AlexNet(\n  (conv): Sequential(\n    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU()\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU()\n    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU()\n    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU()\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc): Sequential(\n    (0): Linear(in_features=6400, out_features=4096, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=10, bias=True)\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "print(net)"
   ]
  },
  {
   "source": [
    "### 读取数据"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "``组合实现``一个``transform``,对输入图像进行变换,将图像高和宽扩大到AlexNet使用的高和宽224."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = 224\n",
    "trans = []\n",
    "trans.append(torchvision.transforms.Resize(size=resize))\n",
    "trans.append(torchvision.transforms.ToTensor())\n",
    "transform = torchvision.transforms.Compose(trans) # 将两个变换串联起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=True, download=True, transform=transform)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 128\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "source": [
    "### 训练"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print('train on', device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n_train, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # print(\"y.shape\", y.shape) # [128]\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            # train_l_sum += l.cpu().item() # loss复制到cpu上\n",
    "            train_l_sum += l.item()\n",
    "            # train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n_train += y.shape[0]\n",
    "            batch_count += 1\n",
    "        # test_acc = evaluate_accuracy(test_iter, net)\n",
    "        with torch.no_grad():\n",
    "            test_acc_sum, n_test = 0.0, 0 # 创建在内存(CPU)\n",
    "            for X_t, y_t in test_iter:\n",
    "                net.eval() # 评估模式\n",
    "                test_acc_sum += (net(X_t.to(device)).argmax(dim=1) == y_t.to(device)).sum().item()  # 对Tensor进行.item()取值后,得到的就是一个Python Scalar.\n",
    "                net.train() # 训练模式\n",
    "                n_test += y_t.shape[0]\n",
    "            test_acc = test_acc_sum / n_test\n",
    "\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "        % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n_train, test_acc, time.time() - start))"
   ]
  },
  {
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train on cuda\n",
      "epoch 1, loss 0.1484, train acc 0.948, test acc 0.938, time 60.5 sec\n",
      "epoch 2, loss 0.1371, train acc 0.950, test acc 0.875, time 60.3 sec\n",
      "epoch 3, loss 0.1377, train acc 0.951, test acc 1.000, time 60.4 sec\n",
      "epoch 4, loss 0.1291, train acc 0.953, test acc 0.938, time 60.2 sec\n",
      "epoch 5, loss 0.1216, train acc 0.956, test acc 0.875, time 60.1 sec\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}